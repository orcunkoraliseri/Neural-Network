import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import time

'''sample regression example
'''
t = time.time()
# generate random noisy data
x_data = np.linspace(0,10,10) + np.random.uniform(-1.5,1.5,10)
y_label = np.linspace(0,10,10) + np.random.uniform(-1.5,1.5,10)

#plt.plot(x_data,y_label,'*')
#plt.show()

# y = mx + b
m = tf.Variable(0.82) # initialize with random chosen value
b = tf.Variable(0.59) # initialize with random chosen value

# cost function the one that we are trying to minimize
error = 0
for x,y in zip(x_data,y_label):
    y_hat = m*x + b # y_hat = predictied y, linear value
    error += (y-y_hat)**2 # minimize

# in order to minimize we need optimizer
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001) # how fast optimizer will jump
train = optimizer.minimize(error)

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    training_steps = 100

    for i in range(training_steps):
        sess.run(train)

    final_slope, final_intercept = sess.run([m,b])

print('done in:', time.time()-t)


x_test = np.linspace(-1,11,10)
# y = mx + b
y_pred_plot = final_slope*x_test + final_intercept
plt.plot(x_test,y_pred_plot,'r')
plt.plot(x_data,y_label,'*')
plt.show()
